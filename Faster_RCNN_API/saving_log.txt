
Total loss decreased from inf to 2.2130112627393483 in epoch 1/100 in training, saving weights
Total loss decreased from inf to 2.4806366552512973 in epoch 1/100 in training, saving weights
Total loss decreased from 2.4806366552512973 to 1.8940926671060352 in epoch 2/100 in training, saving weights
Total loss decreased from 1.8940926671060352 to 1.7973216873444888 in epoch 3/100 in training, saving weights
Total loss decreased from inf to 1.5903417576192251 in epoch 3/100 in validation, saving weights
Total loss decreased from 1.7973216873444888 to 1.5814581927005134 in epoch 4/100 in training, saving weights
Total loss decreased from 1.5814581927005134 to 1.2292570080374112 in epoch 5/100 in training, saving weights
Total loss decreased from 1.5903417576192251 to 1.2496654111671877 in epoch 6/100 in validation, saving weights
Total loss decreased from 1.2292570080374112 to 1.017304291940706 in epoch 7/100 in training, saving weights
Total loss decreased from 1.017304291940706 to 0.5636928905674343 in epoch 8/100 in training, saving weights
Total loss decreased from 0.5636928905674343 to 0.3845879327740414 in epoch 9/100 in training, saving weights
Total loss decreased from 1.2496654111671877 to 0.2783627578867381 in epoch 9/100 in validation, saving weights
Total loss decreased from 0.3845879327740414 to 0.26299221249958704 in epoch 10/100 in training, saving weights
Total loss decreased from 0.26299221249958704 to 0.22788224713209865 in epoch 11/100 in training, saving weights
Total loss decreased from 0.22788224713209865 to 0.21831702213323878 in epoch 12/100 in training, saving weights
Total loss decreased from 0.2783627578867381 to 0.20389521043347147 in epoch 12/100 in validation, saving weights
Total loss decreased from 0.21831702213323878 to 0.20710705211750924 in epoch 13/100 in training, saving weights
Total loss decreased from 0.20710705211750924 to 0.18746957025693894 in epoch 14/100 in training, saving weights
Total loss decreased from 0.18746957025693894 to 0.1770873281171838 in epoch 15/100 in training, saving weights
Total loss decreased from 0.20389521043347147 to 0.18229059121075536 in epoch 15/100 in validation, saving weights
Total loss decreased from 0.1770873281171838 to 0.15634507968362027 in epoch 16/100 in training, saving weights
Total loss decreased from 0.15634507968362027 to 0.1497248101906377 in epoch 17/100 in training, saving weights
Total loss decreased from 0.1497248101906377 to 0.12773077816549194 in epoch 18/100 in training, saving weights
Total loss decreased from 0.18229059121075536 to 0.13380542606542992 in epoch 18/100 in validation, saving weights
Total loss decreased from 0.12773077816549194 to 0.12243376670410597 in epoch 19/100 in training, saving weights
Total loss decreased from 0.12243376670410597 to 0.11648456092003437 in epoch 20/100 in training, saving weights
Total loss decreased from 0.11648456092003437 to 0.1109291485777578 in epoch 21/100 in training, saving weights
Total loss decreased from 0.13380542606542992 to 0.12608389746010173 in epoch 21/100 in validation, saving weights
Total loss decreased from 0.12608389746010173 to 0.09645582664473298 in epoch 24/100 in validation, saving weights
Total loss decreased from 0.1109291485777578 to 0.0830771265745914 in epoch 27/100 in training, saving weights
Total loss decreased from 0.09645582664473298 to 0.07816237068811499 in epoch 27/100 in validation, saving weights
Total loss decreased from 0.07816237068811499 to 0.06616454203026641 in epoch 33/100 in validation, saving weights
Total loss decreased from 0.0830771265745914 to 0.07921715560470305 in epoch 34/100 in training, saving weights
Total loss decreased from 0.07921715560470305 to 0.06603623140277666 in epoch 35/100 in training, saving weights
Total loss decreased from 0.06603623140277666 to 0.06386828280483824 in epoch 36/100 in training, saving weights
Total loss decreased from 0.06386828280483824 to 0.06059882079262072 in epoch 37/100 in training, saving weights
Total loss decreased from 0.06059882079262072 to 0.05987410722105077 in epoch 38/100 in training, saving weights
Total loss decreased from 0.05987410722105077 to 0.05224687306657795 in epoch 39/100 in training, saving weights
Total loss decreased from 0.05224687306657795 to 0.05167738654658855 in epoch 40/100 in training, saving weights
Total loss decreased from 0.05167738654658855 to 0.0436349435435083 in epoch 44/100 in training, saving weights
Total loss decreased from 0.0436349435435083 to 0.03486999294855303 in epoch 46/100 in training, saving weights
Total loss decreased from 0.03486999294855303 to 0.027399127847893997 in epoch 47/100 in training, saving weights
Total loss decreased from 0.027399127847893997 to 0.02718388316534554 in epoch 48/100 in training, saving weights
Total loss decreased from 0.06616454203026641 to 0.01958397845484541 in epoch 48/100 in validation, saving weights
Total loss decreased from 0.02718388316534554 to 0.02476456321568751 in epoch 52/100 in training, saving weights
Total loss decreased from 0.02476456321568751 to 0.02475293589367892 in epoch 59/100 in training, saving weights
Total loss decreased from 0.01958397845484541 to 0.018965511864166087 in epoch 60/100 in validation, saving weights
Total loss decreased from 0.02475293589367892 to 0.023002425675055383 in epoch 64/100 in training, saving weights
Total loss decreased from 0.023002425675055383 to 0.02226180730682902 in epoch 65/100 in training, saving weights
Total loss decreased from 0.02226180730682902 to 0.013760427031960112 in epoch 66/100 in training, saving weights
Total loss decreased from 0.018965511864166087 to 0.016859912391473147 in epoch 66/100 in validation, saving weights
Total loss decreased from 0.016859912391473147 to 0.00816257008284425 in epoch 75/100 in validation, saving weights